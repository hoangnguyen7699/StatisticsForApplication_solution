\documentclass[10pt]{article}
\usepackage{hyperref}
\usepackage[margin=1in]{geometry} 
\usepackage{amsmath,amsthm,amssymb, graphicx, multicol, array}

\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
 
\newenvironment{problem}[2][Problem]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}



\begin{document}
\title{Problem Set 10}
\author{Hoang Nguyen, Huy Nguyen}
\maketitle
    
\begin{problem}{1}
\item 1.
We have PDF: $p(x) = p^{x}(1-p)^{1-x} = e^{xlog(p) + (1-x)log(1-p)}$. Hence we have: 
\[\begin{cases} \eta_{1}=log(p) \\ \eta_{2} = log(1-p) \\ T_{1}(x)= x \\ T_{2}(x)=1-x \\ h(x) = 1 \\ B(p)=0   \end{cases} \]




\item 2. 
We have PDF $p(x) = e^{\mu x- \frac{\mu^2}{2}}\frac{e^{\frac{-x^{2}}{2}}}{\sqrt{2\pi}}$.Hence
\[\begin{cases} \eta=\mu \\  T(x)= x  \\ h(x) = \frac{e^{\frac{-x^{2}}{2}}}{\sqrt{2\pi}} \\ B(p)=\frac{\mu^2}{2}   \end{cases} \]




\item 3. 
We have PDF $p(x) = e^{\frac{\mu}{\sigma^2} - \frac{1}{2\sigma^2}x^{2} - \frac{\mu^2}{2\sigma^2}}\frac{1}{\sigma\sqrt{2\pi}}$. Hence
\[ \begin{cases} \eta_{1}=\frac{\mu}{\sigma^2} \\ \eta_{2} = -\frac{1}{2\sigma^2} \\ T_{1}(x)= x \\ T_{2}(x)=x^{2} \\ h(x) = 1 \\ B(p)=\frac{\mu^2}{2\sigma^2} + log(\sigma\sqrt{2\pi})   \end{cases} \]

\item 4.
We have $p(x) = \lambda e^{-\lambda x}$. Hence
\[ \begin{cases} \eta=-\lambda \\  T(x)= x  \\ h(x) = \lambda \\ B(p)=0   \end{cases}\]

\item 5.
We have $p(x)= \frac{1}{\upsilon} = e^{-log(\upsilon)}$. Hence
We have $p(x) = \lambda e^{-\lambda x}$. Hence
\[ \begin{cases} \eta=-log(\upsilon) \\  T(x)= 1  \\ h(x) = 1 \\ B(p)=0   \end{cases}\]

\item 6.
We have $p(x) = \frac{\beta^{\alpha}}{\mathbb{I}(\alpha)}x^{\alpha - 1}e^{-\beta x} = e^{-\beta x + (\alpha -1)log(x)}\frac{\beta^{\alpha}}{\mathbb{I}(\alpha)}$. Hence
\[\begin{cases} \eta_{1}=-\beta \\ \eta_{2} = \alpha -1 \\ T_{1}(x)= x \\ T_{2}(x)=log(x) \\ h(x) = 1 \\ B(p)= -log(\frac{\beta^{\alpha}}{\mathbb{I}(\alpha)})   \end{cases} \] 

\item 7.
We have $p(x) = \frac{\lambda^{x} e^{-\lambda}}{x!} = e^{-\lambda + log(\lambda) x}\frac{1}{x!}$. Hence
\[\begin{cases} \eta_{1}=log(\lambda)\\  T(x)= x \\  h(x) = \frac{1}{x!} \\ B(p)= -\lambda   \end{cases} \]

\end{problem}

\begin{problem}{2}
\item 1. \\
a) \\
b) We have 
\[\mathbb{E}[\frac{\partial log(f_{\theta}(x))}{\partial \theta}] = \mathbb{E}[\frac{\frac{\partial }{\partial \theta} f_{\theta}(x)}{f_{\theta}(x)}] = \int \frac{\frac{\partial }{\partial \theta} f_{\theta}(x)}{f_{\theta}(x)} f_{\theta}(x) = \frac{\partial }{\partial \theta} \int f_{\theta}(x)dx = 0 \]

\[\mathbb{E}[\frac{\partial^2}{\partial \theta^2} log(f_{\theta}(x))] = \int \frac{[\frac{\partial^2}{\partial \theta^2} f_{\theta}(x)] f_{\theta}(x) - [\frac{\partial}{\partial \theta} f_{\theta}(x)]^2 }{(f_{\theta}(x))^2} f_{\theta}(x) = \int \frac{\partial^2}{\partial \theta^2} f_{\theta}(x) + \int \Big ( \frac{[\frac{\partial}{\partial \theta} f_{\theta}(x)]^2}{f_{\theta}(x)}dx \Big ) = \mathbb{E}[(\frac{\frac{\partial}{\partial \theta}f_{\theta} (x)}{f_{\theta (x)}})^2 ] \]
We have $l(\theta) = -\theta x + b(\theta) + log(a(x))$. Hence $l'(\theta) = -x + b'(\theta) $ and $l''(\theta) = b''(\theta)$. From previous quantities, $\mathbb{E}[l'(\theta)]= - \mathbb{E}[x] + b'(\theta) =0 $\\
From previous quantities, $\mathbb{E}[\frac{\partial^2}{\partial \theta^2} log(f_{\theta}(x))] = \mathbb{E}[l''(\theta)] = \mathbb{E}[(l'(\theta))^2] $. Because $\mathbb{E}[l'(\theta)] = 0$, hence $\mathbb{E}[(l'(\theta))^2] = var(l'(\theta)) = -  \mathbb{E}[l''(\theta)]$\\
c) Fisher Information.
\item 2.\\
From previous questions, we have $l'(\theta) = -x + b'(\theta)$ and $l''(\theta) = b''(\theta)$
\item 3. \\
From previous result $ \mathbb{E}[l'(\theta)]-\mathbb{E}[x] + b'(\theta)=0 \Rightarrow \mathbb{E}[x]=b'(\theta)$\\
From previous result $\mathbb{E}[(l'(\theta))^2] = \mathbb{E}[(-x + b'(\theta))^2] = \mathbb{E}[(-x + E[x])^2] = var(x) =- b''(\theta)$
\item 4. \\
a) Sample space $X=(0, + \infty)$\\
b) $a(x)= x^{\alpha -1}$ and $b(\theta) = log(\frac{\theta^{\alpha}}{\mathbb{I}(\alpha)})$
c) From previous result, $\mathbb{E}[x]=b'(\theta)= \frac{\alpha}{\theta}$ and $Var(x)=-b''(\theta)= \frac{\alpha}{\theta^2}$

\end{problem}
\begin{problem}{3}
\item 1. $Z_{1}$ is either 0 or 1, hence $Z_{1}$ is Bernoulli distribution conditional on $X_{i}$ with parameter $p=F(-X^{T}\beta)$.
\item 2. We have $\mathbb{E}[Z]=p=F(-X^{T}\beta)$. Hence $g(F(-X^{T}\beta)) = X^{T}\beta \Rightarrow g(x)=-F^{-1}(x)$.
\item 3. If $\epsilon$ is standard Gaussian, becasue CDF of standard Gaussian is even function, hence $F(x)=-F(x) \Rightarrow g(x)=-F^{-1}(x)=F^{-1}(x)$. 
\item 4. \\
a) $F(t)= \int \frac{e^{-t}}{(1+e^{-1})^2} = -\frac{e^{-t}}{1+e^{-t}}$\\
b) $g(x)= -F^{-1}(x)=log(\frac{x}{1-x})$\\
c) This link is called logit link.




\end{problem}

\end{document}