\documentclass[10pt]{article}
\usepackage{hyperref}
\usepackage[margin=1in]{geometry} 
\usepackage{amsmath,amsthm,amssymb, graphicx, multicol, array}
 
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
 
\newenvironment{problem}[2][Problem]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}



\begin{document}
\title{Problem Set 5}
\author{Hoang Nguyen, Huy Nguyen}
\maketitle
    
\begin{problem}{1}
\item 1.
From exercise 3 in Problem 2, If $Z \thicksim N(0,1)$, we get: $\mathbb{P}\Big[|\frac{\sqrt{n}(\bar{X_i}-\mu)}{\sigma}| \leqslant t\Big]=2\mathbb{P}[Z \leqslant t]-1$.\\
$X_1, X_2,...,X_n$ follow Poisson distribution. Hence, $\mathbb{E}[X_i]=\lambda$ and $\mathbb{V}[X_i]=\lambda$\\
From CTL: $\frac{\sqrt{n}(\bar{X_n}-\lambda)}{\sqrt{\lambda}} \thicksim N(0,1)$. Hence, $\mathbb{P}\Big [ |\frac{\sqrt{n}(\bar{X_n}-\lambda)}{\sqrt{\lambda}}| \leqslant t \Big]=2\mathbb{P}\Big [ \frac{\sqrt{n}(\bar{X_n}-\lambda)}{\sqrt{\lambda}} \leqslant t \Big ]-1=1-\alpha.$\\
Hence, $\mathbb{P}\Big [ \frac{\sqrt{n}(\bar{X_n}-\lambda)}{\sqrt{\lambda}} \leqslant t \Big ]=1- \frac{\alpha}{2}$. Therefore, $t=\phi^{-1}(1- \frac{\alpha}{2}).$\\
We have $ = \mathbb{P}\Big [ |\frac{\sqrt{n}(\bar{X_n}-\lambda)}{\sqrt{\lambda}}| \leqslant \phi^{-1}(1- \frac{\alpha}{2}) \Big ]\rightarrow (1-\alpha)$ as n tends to infinity. This equivalent to:
\[  \mathbb{P}\Big[-\frac{\sqrt{n}(\bar{X_n}-\lambda)}{\sqrt{\lambda}} \leqslant \phi^{-1}(1- \frac{\alpha}{2}) \leqslant \frac{\sqrt{n}(\bar{X_n}-\lambda)}{\sqrt{\lambda}}\Big] \rightarrow 1-\alpha\] 
\[ \mathbb{P}\Big[\bar{X_n}- \frac{\phi^{-1}(1- \frac{\alpha}{2})\sqrt{\lambda}}{\sqrt{n}} \leqslant \lambda \leqslant \bar{X_n}+ \frac{\phi^{-1}(1- \frac{\alpha}{2})\sqrt{\lambda}}{\sqrt{n}}  \Big] \rightarrow 1- \alpha\]
We know: $\bar{X_n} \xrightarrow{P} \mathbb{E}[\bar{X_n}]=\lambda$\\
Hence, 
\[ \mathbb{P}\Big[\bar{X_n}- \frac{\phi^{-1}(1- \frac{\alpha}{2})\sqrt{\bar{X_n}}}{\sqrt{n}} \leqslant \lambda \leqslant \bar{X_n}+ \frac{\phi^{-1}(1- \frac{\alpha}{2})\sqrt{\bar{X_i}}}{\sqrt{n}}  \Big] \geqslant 1- \alpha\]
$\Rightarrow$ L=[$\bar{X_n}- \frac{\phi^{-1}(1- \frac{\alpha}{2})\sqrt{\bar{X_i}}}{\sqrt{n}}, \bar{X_n}+ \frac{\phi^{-1}(1- \frac{\alpha}{2})\sqrt{\bar{X_i}}}{\sqrt{n}}$]


\item 2. 
From previous result, if $\lambda_0 \in L$, we do not reject $H_0$. Otherwise, there is evidence to reject $H_0$.

















\end{problem}

\begin{problem}{2}
\item 1.
Take derivative of Gaussian expression respect to $\mu_1, \sigma_1, \mu_2, \sigma_2$ and set it equals to 0, we get:\\
$\hat{\mu_1}=\bar{X_{n1}}$, $\hat{\mu_2}=\bar{Y_{n2}}$, $\hat{\sigma_1}^2=\frac{1}{n1}\sum_{i=1}^{n1} (X_i-\hat{\mu_1})^2$ and $\hat{\sigma_2}^2=\frac{1}{n1}\sum_{i=1}^{n2} (Y_i-\hat{\mu_2})^2$.

\item 2.
We have: $\frac{n_1\hat{\sigma_1}^2}{\sigma_1^2}=\frac{n_1\frac{1}{n1}\sum_{i=1}^{n_1} (X_i-\mu_1)^2}{\sigma_1^2}=\sum_{i=1}^{n_1}(\frac{X_i-\mu_1}{\sigma_1})^2$. Since $\frac{X_i-\mu_1}{\sigma_1}\sim N(0,1)$, hence $\frac{n_1\hat{\sigma_1}^2}{\sigma_1^2} \sim \chi_{n1}^2$.\\
By similar method, we get $\frac{n_2\hat{\sigma_2}^2}{\sigma_2^2} \sim \chi_{n2}^2$






\item 3.
From previous result, $\frac{n_1\hat{\sigma_1}^2}{\sigma_1^2} + \frac{n_2\hat{\sigma_2}^2}{\sigma_2^2} \sim \chi_{n1}^2 + \chi_{n2}^2 \sim \chi_{n1+n2}^2$.


\item 4.
From CTT, $\bar{X_{n1}} \sim N(\mu_1, \sigma_1^2)$, $\bar{X_{n2}} \sim N(\mu_2, \sigma_2^2)$. Hence, $\Delta=\hat{\mu_1}-\hat{\mu_2}=\bar{X_{n1}}- \bar{X_{n2}} \sim N(\mu_1-\mu_2, \sigma_1^2+\sigma_2^2)$.


\item 5.
From the previous question, we get $\Delta=\hat{\mu_1}-\hat{\mu_2}=\bar{X_{n1}}- \bar{X_{n2}} \sim N(\mu_1-\mu_2, \sigma_1^2+\sigma_2^2)$.\\
Under $H_0$: $\Delta \sim N(0,\sqrt{ \sigma_1^2+\sigma_2^2})$. Hence, $\frac{\Delta}{\sigma_1^2+\sigma_2^2} \rightarrow \frac{\Delta}{\sqrt{\hat{\sigma_1}^2 + \hat{\sigma_2}^2}} \sim N(0,1)$.\\
Let's denote test statistic $T=\Big | \frac{\Delta}{\sqrt{\hat{\sigma_1}^2 + \hat{\sigma_2}^2}}\Big |$. We now $\mathbb{P}[T > c]=\alpha$, hence $c=1-\phi^{-1}(\frac{\alpha}{2})$.\\
Conclusion: If $T>c$, we reject $H_0$, otherwise, we fail to reject $H_0$.


\item 6.
In this case, from the previous qeuestion, we have $T=\Big | \frac{\Delta}{\sqrt{\hat{\sigma_1}^2 + \hat{\sigma_2}^2}}\Big |=\frac{8.43-8.07}{\sqrt{0.22+0.17}}=0.5765$. Morever, $c=\phi^{-1}(1-\frac{\alpha}{2})=\phi^{-1}(0.975)=1.96$. Because $T<c$, we fail to reject $H_0$ which means we can conclude two machines are significantly identical.\\
p-value=$\mathbb{P}[|N(0,1)|>0.5765]=1-\mathbb{P}[|N(0,1)| \leqslant 0.5765]=1-(2\mathbb{P}[N(0,1) \leqslant 0.5765]-1)=2-2\phi(0.5765)=0.5642$.




\end{problem}

\begin{problem}{3}
Let denote the function $\mathbb{R}^{2} \longrightarrow \mathbb{R}: g(\mu, \sigma^2)=\mu -\sqrt{\sigma^2}$. We have:
\[ \frac{\partial g}{\partial \mu}=1 \]
\[ \frac{\partial}{\partial \sigma^{2}}= -\frac{1}{2\sigma}\]
Let denote $\hat{\mu}=\bar{X_n}$ and $\hat{\sigma}^{2}=\frac{1}{n}\sum(X_i-\hat{\mu})^{2}$. Hence, by \href{https://alecospapadopoulos.files.wordpress.com/2016/03/asympt-distr-of-sample-variance-dichotomous-rvs-technical-report.pdf}{this result}: 
\[ \sqrt{n}(\hat{\mu}-\mu) \longrightarrow N(0, \sigma^2).\]
\[ \sqrt{n}(\hat{\sigma^2}- \sigma^2) \longrightarrow N(0, 2\sigma^{4}) \]
Hence $(\hat{\mu}, \hat{\sigma^2})$ is asymptotically normal with covariance matrix:
\[\sum= 
\begin{bmatrix}
    \sigma^2 & 0\\
    0 & 2\sigma^4
\end{bmatrix}
 \] 
Using Delta method we have: 
\[ \sqrt{n}(g(\hat{\mu}, \hat{\sigma}^2) - g(\mu, \sigma^2)) \longrightarrow N(0, \nabla_{\mu, \sigma^2}^{T} \Sigma \nabla_{\mu, \sigma^2} ))\]
Where $\nabla_{\mu, \sigma^2}= \nabla g(\mu, \sigma^2)=[1 -\frac{1}{2\sigma}]^{T}$. Hence $\nabla_{\mu, \sigma^2}^{T} \Sigma \nabla_{\mu, \sigma^2}=[1 -\frac{1}{2\sigma}]\begin{bmatrix}
    \sigma^2 & 0\\
    0 & 2\sigma^4
\end{bmatrix} 
\begin{bmatrix}
    1 \\
     -\frac{1}{2\sigma}
\end{bmatrix}=\frac{3}{2}\sigma^2$.\\
Hence $ \sqrt{n}(g(\hat{\mu}, \hat{\sigma}^2) - g(\mu, \sigma^2)) \longrightarrow N(0, \frac{3}{2}\sigma^2 )) $ which equivalents to $ \sqrt{n}\frac{\sqrt{\frac{2}{3}}}{\sigma}(g(\hat{\mu}, \hat{\sigma}^2) - g(\mu, \sigma^2)) \longrightarrow N(0, 1)$. Computing second order Delta method, we have:
\[ n g(\hat{\mu}, \hat{\sigma}^2)^{T} \frac{2}{3\sigma^2} g(\hat{\mu}, \hat{\sigma}^2)  \longrightarrow \chi_{1}^{2}\]
Let denote c is $(1-\alpha)$-quantile of Kai-square with 1 degree of fredom. Because this is one-sided test statistic, if $T>c$ we reject null hypothesis, othewise, we fail to reject null hypothesis.\\
Consider null hypothesis $H_0:$ $\mu = \sigma$\\
In our case, under null hypothesis, $T=n g(\hat{\mu}, \hat{\sigma}^2)^{T} \frac{2}{3\sigma^2} g(\hat{\mu}, \hat{\sigma}^2) =  100 \times (2.41-\sqrt{5.2}) \times \frac{2}{3\times 5.2} \times (2.41-\sqrt{5.2})= 0.215 $ and $c=3.841$. Since $T<c$, we fail to reject $H_0$: $\mu = \sigma$. Hence, we also fail to reject $H_0$: $\mu<\sigma$.\\
If the sample size is n = 100, the sample average is 3.28 and the sample variance is 15.95, by similar method, we have $T=2.13$. At level 0.05 we know c=3.841, hence $T<c$ => we fail to reject null hypothesis\\
At level 0.1, we know $c=2.706$. Since $T<c$, we still fail to reject null hypothesis. 

\end{problem}

\end{document}
